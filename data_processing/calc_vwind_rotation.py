"""
Filename:     calc_vwind_rotation.py
Author:       Damien Irving, d.irving@student.unimelb.edu.au
Description:  Calculate meridional wind according to a new coordinate axis 

"""

# Import general Python modules

import sys, os

import argparse
import numpy
import re

import cdms2


# Import my modules

cwd = os.getcwd()
repo_dir = '/'
for directory in cwd.split('/')[1:]:
    repo_dir = os.path.join(repo_dir, directory)
    if directory == 'climate-analysis':
        break

modules_dir = os.path.join(repo_dir, 'modules')
sys.path.append(modules_dir)

try:
    import general_io as gio
    import coordinate_rotation as rot
except ImportError:
    raise ImportError('Must run this script from anywhere within the climate-analysis git repo')


# Define functions

def rotate_vwind(dataU, dataV, new_np, pm_point, res=1.0, anomaly=None):
    """Define the new meridional wind field, according to the 
    position of the new north pole.
    
    FIX: Need a more general method of dealing with input axes
    (e.g. what if there is multiple levels)
    
    """

    assert isinstance(dataU, cdms2.tvariable.TransientVariable)
    assert isinstance(dataV, cdms2.tvariable.TransientVariable)

    assert 'yx' in dataU.getOrder(), \
    'Input data must have a latitude and longitude axis'

    lat_axis = dataU.getLatitude()[:]
    lon_axis = dataU.getLongitude()[:]
    lats, lons = gio.coordinate_pairs(lat_axis, lon_axis)

    # Calculate new vwind on the native grid
    vwind_rot = calc_vwind(dataU, dataV, lat_axis, lon_axis, new_np) 

    if anomaly:
        date_pattern = '([0-9]{4})-([0-9]{1,2})-([0-9]{1,2})'
        if re.search(date_pattern, anomaly[0]) and re.search(date_pattern, anomaly[1]):
            period = anomaly
        else:
            print """Input anomaly base period either invalid format or 'all' - base climatology is entire period"""
            period = None
	
	vwind_rot = cdms2.createVariable(vwind_rot, grid=dataU.getGrid(), axes=dataU.getAxisList())
	vwind_rot = temporal_aggregation(vwind_rot, 'ANNUALCYCLE', 'anomaly', time_period=period)  #hard wired to annual cycle

    # Rotate the coordinate axis to desired grid
    nlats = int((180.0 / res) + 1)
    nlons = int(360.0 / res)
    grid = cdms2.createUniformGrid(-90.0, nlats, res, 0.0, nlons, res)
    lat_axis_rot = grid.getLatitude()
    lon_axis_rot = grid.getLongitude()
     
    vwind_rot_switch = rot.switch_regular_axes(vwind_rot, lats, lons, lat_axis_rot[:], lon_axis_rot[:], new_np, pm_point=pm_point, invert=True)
    
    if 't' in dataU.getOrder():
        axis_list = [dataU.getTime(), lat_axis_rot, lon_axis_rot]
    else: 
        axis_list = [lat_axis_rot, lon_axis_rot]
    
    vwind_rot_swtich = cdms2.createVariable(vwind_rot_switch, grid=grid, axes=axis_list)
    
    return vwind_rot, vwind_rot_swtich    
        

def calc_vwind(dataU, dataV, lat_axis, lon_axis, new_np, old_np=(90.0, 0.0)):
    """Calculate the new meridional wind field, according to the
    new position of the north pole."""
    
    lats, lons = gio.coordinate_pairs(lat_axis, lon_axis) 
    theta = rot.rotation_angle(old_np[0], old_np[1], new_np[0], new_np[1], 
                               lats, lons, reshape=[len(lat_axis), len(lon_axis)])
    theta = numpy.resize(theta, numpy.shape(dataU))
    
    dataV_rot = vwind_trig(dataU, dataV, theta) 

    return dataV_rot  
    
    
def vwind_trig(u, v, theta):
    """Calculate new meridional wind from the old one.

    Args:
      u (array): zonal wind data
      v (array): meridional wind data
      theta (float): angle through which the x/y coordinate axes must 
        be rotated, measured anticlockwise starting on the original positive 
        x-axis (i.e. at 90 deg in a 360 circle)
               
    """
    
    wsp = numpy.sqrt(numpy.square(numpy.array(u)) + numpy.square(numpy.array(v)))
    
    # Calculate the angle (phi) that the wind vector makes with the original
    # positive x-axis (measured anticlockwise starting on the original 
    # positive x-axis) 
    phi = numpy.arctan2(v, u) 

    # Calculate the angle (alpha) that the wind vector makes with the new positive 
    # x-axis (measured anticlockwise starting on the new positive x-axis)
    alpha = phi - theta
    
    return wsp * numpy.sin(alpha)


def subset_kwargs(namespace):
    """Get keyword arguments for cdms2 subsetting.
    
    namespace is usually generated by argparse at the beginning of a script.
    Args:
      namespace (argparse.Namespace) 
    
    """

    kwarg_dict = {}
    try:
        south_lat, north_lat, west_lon, east_lon = regions[namespace.region]
        kwarg_dict['latitude'] = (south_lat, north_lat)
	kwarg_dict['longitude'] = (west_lon, east_lon)
    except AttributeError:
        pass     

    try:
        kwarg_dict['time'] = namespace.time    
    except AttributeError:
        pass 

    return kwarg_dict


def temporal_aggregation(data, output_timescale, output_quantity, time_period=None):
    """Create a temporal aggregate of the input data, or further process it
    to produce a climatology or anomaly timeseries.
    Reference: http://www2-pcmdi.llnl.gov/cdat/source/api-reference/cdutil.times.html
    
    The cdutil season averager is smart and accounts for the number of days in each 
    month (i.e. months with more days are weighted more heavily in the average)
    Args:
      data (cdms2.tvariable.TransientVariable): Input data
      output_timescale (str): Can be SEASONALCYCLE (i.e. DJF/MAM/JJA/SON), ANNUALCYCLE 
        (i.e. JAN/FEB/MAR/.../DEC), year, season(DJF,MAM,JJA,SON), month (JAN,...,DEC) or
        any custom season (e.g. MJJASO, DJFM)
      output_quantity (str): Can be 'raw', 'climatology' or 'anomaly'
      time_period (list of str, optional): For climatology used in calculating the anomaly
        ['lower_bound', 'upper_bound'] e.g. ['1979-01-01', '1980-12-31']
        
    """

    assert isinstance(data, cdms2.tvariable.TransientVariable)
    assert output_quantity in ['raw', 'climatology', 'anomaly']

    accepted_timescales = ['SEASONALCYCLE', 'ANNUALCYCLE', 'YEAR',
                           'DJF', 'MAM', 'JJA', 'SON',
                           'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN',
                           'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC']
    double_alphabet = 'JFMAMJJASONDJFMAMJJASOND'
    assert (output_timescale in accepted_timescales) or \
           (output_timescale in double_alphabet) or \
           (output_timescale.lower() == 'input')
   
    if time_period:
        assert len(time_period) == 2, \
        """time_period should be a list or tuple of length 2. e.g. ('1979-01-01', '1980-12-31')"""

    time_axis = data.getTime().asComponentTime()
    input_timescale = get_timescale(get_datetime(time_axis[0:2]))
   
    # Set time bounds
    daily_freq = {'hourly': 24, '6hourly': 4, '12hourly': 2, 'daily': 1}
    if input_timescale in daily_freq.keys():
        cdutil.setTimeBoundsDaily(data, frequency=daily_freq[input_timescale])
    elif input_timescale == 'monthly':
        cdutil.setTimeBoundsMonthly(data)
    elif input_timescale == 'yearly':
        cdutil.setTimeBoundsYearly(data)
    else:
        print 'Unrecognised input timescale.'
        print 'Must be daily, monthly or yearly.'
        sys.exit(1)

    # Extract subset of interest
    if output_timescale in accepted_timescales:
        season = eval('cdutil.' + output_timescale)
    elif output_timescale in double_alphabet:
        season = cdutil.times.Seasons(output_timescale)

    if output_quantity == 'raw':
        outdata = season(data, criteriaarg=[1.0, None])   #e.g. means for DJF, the D, J and F data must all be available or else set to missing
    elif output_quantity == 'climatology':
        outdata = season.climatology(data, criteriaarg=[1.0, None])
    elif output_quantity == 'anomaly':
        clim = season.climatology(data(time=time_period), criteriaarg=[1.0, None]) if time_period else season.climatology(data, criteriaarg=[1.0, None])
        assert type(clim) != type(None), \
        'Input data are of insufficient temporal extent to calculate climatology'   
        outdata = season.departures(data, ref=clim)

    assert type(outdata) != type(None), \
    'Input data are of insufficient temporal extent to calculate the requested temporal aggregation (%s)' %(output_quantity)

    return outdata


def write_netcdf(outfile_name, history_entry, global_atts, 
                 outdata, outvar_atts, outvar_axes, 
                 clear_history=False, extra_history=' '):
    """Write an output netCDF file.
    
    Intended for use with a calculated quantity. Many attributes and axes are copied 
    from the existing input files.
    
    All output variables must have the axes.
    
    Args:
      outfile_name (str): Name of output file
      history_entry (str): Entry for the global history attribute (usually generated 
        from " ".join(sys.argv))
      global_atts (dict): Global attributes for output file (usually obtained from 
        InputData instances via the .global_atts attribute)
      outdata (list of numpy.ndarray): Data for each output variable
      outvar_atts (list of dict): Attributes for each output variable. Suggested minumum 
        attributes include: id, long_name, missing_value, units, notes
      outvar_axes (list of lists): Axis lists for each outdata element (must be in order 
        tyx). Should be generated using the cdat getTime(), getLatitude() or 
        getLongitude() methods
      clear_history (bool, optional): Set true to not append the global 'history' 
        attribute to the corresponding attribute in the output file
      extra_history (str, optional): String of extra info to be added to the standard
        global 'history' attribute output     
    """

    assert type(global_atts) == dict
    
    assert isinstance(outdata, (list, tuple)), \
    '4th argument (outdata) must be a list or tuple of data arrays, e.g. (data,)'
    
    assert isinstance(outvar_atts, (list, tuple)) and type(outvar_atts[0]) == dict, \
    '5th argument (outvar_atts) must be a list or tuple of dictionaries, e.g. (atts,)'
    
    assert isinstance(outvar_axes, (list, tuple)), \
    '6th argument (outvar_axes) must be a list or tuple of axis lists or tuples, e.g. (data.getTime(),)'
    
    for axes in outvar_axes:
        index = 0
        for axis in axes:
            test = (axis.isTime(), axis.isLatitude(), axis.isLongitude())
            assert sum(test) == 1 and test.index(1) >= index, \
            '6th argument (outvar_axes) elements must a time, latitude or longitude axis, in that order'
            index = test.index(1)

    outfile = cdms2.open(outfile_name, 'w')
    
    # Global attributes
    for att_name in global_atts.keys():
        if att_name not in ["history", "calendar"]:  # Calendar excluded because iris doesn't like it
            setattr(outfile, att_name, global_atts[att_name])
    
    if not clear_history:
        old_history = global_atts['history'] if ('history' in \
                      global_atts.keys()) else ''
    else:
        old_history = ''
    
    timestamp = gio.get_timestamp()
    setattr(outfile, 'history', 
    """%s [format=NETCDF3_CLASSIC]. %s\n%s""" %(timestamp, extra_history, old_history))

    # Variables
    nvars = len(outdata)
    for index in range(0, nvars):
        outvar_axis_list = []
        for axis in outvar_axes[index]:
            outvar_axis_list.append(outfile.copyAxis(axis))
        var = cdms2.MV2.array(outdata[index])
        var = var.astype(numpy.float32)
        var.setAxisList(outvar_axis_list)
        for key, value in outvar_atts[index].iteritems():
            setattr(var, key, value)
        outfile.write(var)  
    outfile.close()

     
def main(inargs):
    """Run the program."""
    
    # Prepare input data
    subset_dict = subset_kwargs(inargs)

    ufin = cdms2.open(inargs.infileU)
    indataU = ufin(inargs.variableU, **subset_dict)

    vfin = cdms2.open(inargs.infileV)
    indataV = vfin(inargs.variableV, **subset_dict)
    
    # Calulate the new vwind
    vwind_rot, vwind_rot_switch = rotate_vwind(indataU.data, indataV.data, inargs.north_pole, inargs.pm, anomaly=inargs.anomaly)

    # Write the output file
    if inargs.noswitch:
        grid_insert = '(although the data are still stored on a non-rotated grid)'
    else:
        grid_insert = '(the data are stored on the rotated/shifted grid)' 

    if inargs.anomaly:
        standard_name = 'rotated_meridional_wind_anomaly'
	long_name = 'Meridional wind anomaly for a shifted north pole %s' %(grid_insert)
        clim = 'Base period: %s - %s' %(inargs.anomaly[0], inargs.anomaly[1])
    else:
        standard_name = 'rotated_meridional_wind'
	long_name = 'Meridional wind for a shifted north pole %s' %(grid_insert)
	clim = ''  

    notes = 'Location of north pole: %s N, %s E. Prime meridian point = %s N, %s E. %s' %(str(inargs.north_pole[0]), str(inargs.north_pole[1]), 
											    str(inargs.pm[0]), str(inargs.pm[1]), clim)
    vrot_atts = {'id': 'vrot',
                 'standard_name': standard_name,
                 'long_name': long_name,
                 'units': indataU.data.units,
                 'notes': notes}
											    
    outdata_list = [vwind_rot,] if inargs.noswitch else [vwind_rot_switch,]
    outvar_atts_list = [vrot_atts,]
    outvar_axes_list = [vwind_rot.getAxisList(),] if inargs.noswitch else [vwind_rot_switch.getAxisList(),]
 
    write_netcdf(inargs.outfile, " ".join(sys.argv), 
                 indataU.global_atts, 
                 outdata_list,
                 outvar_atts_list, 
                 outvar_axes_list)


if __name__ == '__main__':

    extra_info =""" 
example (abyss.earthsci.unimelb.edu.au):
  /usr/local/uvcdat/1.2.0rc1/bin/cdat calc_vwind_rotation.py 
  /work/dbirving/datasets/Merra/data/ua_Merra_250hPa_monthly_native.nc ua
  /work/dbirving/datasets/Merra/data/va_Merra_250hPa_monthly_native.nc va 
  /work/dbirving/datasets/Merra/data/processed/vrot_Merra_250hPa_monthly-anom-wrt-all_y181x360_np30-270.nc
  --north_pole 30 270
  --anomaly all all
  --grid -90.0 181 1.0 0.0 360 1.0

required improvements:
  1. There might be some funny point in the grid switch that need to be looked at. This
     might be able to be fixed by using a higher resolution grid.

author:
  Damien Irving, d.irving@student.unimelb.edu.au

"""

    description='Rotate grid and calculate new meridional wind'
    parser = argparse.ArgumentParser(description=description,
                                     epilog=extra_info, 
                                     argument_default=argparse.SUPPRESS,
                                     formatter_class=argparse.RawDescriptionHelpFormatter)

    parser.add_argument("infileU", type=str, help="Input file name, containing the zonal wind")
    parser.add_argument("variableU", type=str, help="Input file variable, for the zonal wind")
    parser.add_argument("infileV", type=str, help="Input file name, containing the meridional wind")
    parser.add_argument("variableV", type=str, help="Input file variable, for the meridional wind")
    parser.add_argument("outfile", type=str, help="Output file name")

    parser.add_argument("--region", type=str, choices=gio.regions.keys(),
                        help="Region [default = entire]")
    parser.add_argument("--time", type=str, nargs=2, metavar=('START_DATE', 'END_DATE'),
                        help="Time period [default = entire]")

    parser.add_argument("--north_pole", type=float, nargs=2, metavar=('LAT', 'LON'), default=[90.0, 0.0],
                        help="Location of north pole [default = (90, 0)] - (30, 270) for PSA pattern")
    parser.add_argument("--pm", type=float, nargs=2, metavar=('LAT', 'LON'), default=(0.0, 0.0),
                        help="Location of the prime meridian point")	
    parser.add_argument("--anomaly", type=str, nargs=2, metavar=('START_DATE', 'END_DATE'), default=None,
                        help="""Output the anomaly timeseries (calculated from annual cycle monthly climatology). Each date can be 'all' or 'YYYY-MM-DD' [default=False]""")
    parser.add_argument("--noswitch", action="store_true", default=False,
                        help="Switch for outputing the vwind on the original grid, as opposed to the switched (or rotated) grid [default: False]") 	
    
    args = parser.parse_args()            


    print 'Input files: ', args.infileU, args.infileV
    print 'Output file: ', args.outfile  

    main(args)
